{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(signal):\n",
    "    '''\n",
    "    function returns entropy of a signal\n",
    "    signal must be a 1-D numpy array\n",
    "    '''\n",
    "    lensig=signal.size\n",
    "    symset=list(set(signal))\n",
    "    #numsym=len(symset)\n",
    "    propab=[np.size(signal[signal==i])/(1.0*lensig) for i in symset]\n",
    "    #print(propab)\n",
    "    ent= np.sum([p*np.log2(1.0/p) for p in propab])\n",
    "    #print(ent)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_labels_features(filename_suffix, num_of_centers_array):\n",
    "    \n",
    "    result = []\n",
    "    column_names = []\n",
    "    output_filename = filename_suffix + \"_entropy.csv\"\n",
    "    \n",
    "    for center in num_of_centers_array:\n",
    "        \n",
    "        filename = filename_suffix+ str(center) + \".csv\"\n",
    "        data = pd.read_csv(filename, header=None)\n",
    "\n",
    "        label = data.columns[0]\n",
    "        features= data.columns[1:]\n",
    "\n",
    "        data_features = data[features]\n",
    "        data_label = data[label]\n",
    "\n",
    "        data_features_np = data_features.to_numpy()\n",
    "        data_label_np = data_label.to_numpy()\n",
    "\n",
    "\n",
    "        for i in range(1000):\n",
    "            temp_result = []\n",
    "\n",
    "            sample = data_features_np[i]\n",
    "            temp_result.append(entropy(sample) / math.log2(65536))\n",
    "\n",
    "        result.append(np.mean(temp_result))\n",
    "        column_names.append(filename_suffix + str(center))\n",
    "        \n",
    "    result_pd = pd.DataFrame(result)\n",
    "    result_pd = result_pd.T\n",
    "    combined_result.append(result_pd.values[0])\n",
    "    result_pd.columns = column_names\n",
    "    result_pd.to_csv(output_filename, encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.17917027, 0.1650683 , 0.17971511, 0.22068669, 0.22088211,\n",
      "       0.21175061, 0.23412804, 0.216805  , 0.27223122, 0.2425325 ,\n",
      "       0.24727322, 0.25387811, 0.27253775, 0.24992461, 0.26679592,\n",
      "       0.2579412 , 0.28555176, 0.26539047]), array([0.27408722, 0.25510501, 0.28208373, 0.29178076, 0.24117673,\n",
      "       0.25488245, 0.24044718, 0.21544189, 0.24715016, 0.24318399,\n",
      "       0.22680194, 0.27476238, 0.24062849, 0.24634484, 0.28795611,\n",
      "       0.30089881, 0.22733234, 0.29791755]), array([0.17818896, 0.20774789, 0.22797186, 0.19741757, 0.13592385,\n",
      "       0.13129097, 0.15035767, 0.16346113, 0.16821842, 0.15145225,\n",
      "       0.15785926, 0.16939356, 0.16601462, 0.15468286, 0.15026737,\n",
      "       0.15915204, 0.14652874, 0.15654005]), array([0.30122668, 0.32964884, 0.4306552 , 0.42243478, 0.44261801,\n",
      "       0.4124365 , 0.39767651, 0.42633341, 0.40426555, 0.41865527,\n",
      "       0.41682308, 0.41016799, 0.39407566, 0.37136917, 0.40474522,\n",
      "       0.3873826 , 0.40302244, 0.34042386])]\n"
     ]
    }
   ],
   "source": [
    "combined_column_names = ['10', '30', '50', '70', '90', '110', '130', '150', '170', '190', '210', '230', '250', '270', '290', '310', '330', '350']\n",
    "\n",
    "\n",
    "separate_labels_features(\"test_quantized_ecl_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "separate_labels_features(\"test_quantized_ecl_hungarian_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "separate_labels_features(\"test_quantized_js_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "separate_labels_features(\"test_quantized_js_hungarian_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "\n",
    "\n",
    "print(combined_result)\n",
    "\n",
    "combined_result_pd = pd.DataFrame(combined_result)\n",
    "combined_result_pd.columns = combined_column_names\n",
    "combined_result_pd.to_csv(\"combined_result_ecl_js.csv\", encoding='utf-8', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
