{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(signal):\n",
    "    '''\n",
    "    function returns entropy of a signal\n",
    "    signal must be a 1-D numpy array\n",
    "    '''\n",
    "    lensig=signal.size\n",
    "    symset=list(set(signal))\n",
    "    #numsym=len(symset)\n",
    "    propab=[np.size(signal[signal==i])/(1.0*lensig) for i in symset]\n",
    "    #print(propab)\n",
    "    ent= np.sum([p*np.log2(1.0/p) for p in propab])\n",
    "    #print(ent)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_labels_features(filename_suffix, num_of_centers_array):\n",
    "    \n",
    "    result = []\n",
    "    column_names = []\n",
    "    output_filename = filename_suffix + \"_entropy.csv\"\n",
    "    \n",
    "    for center in num_of_centers_array:\n",
    "        \n",
    "        filename = filename_suffix+ str(center) + \".csv\"\n",
    "        data = pd.read_csv(filename, header=None)\n",
    "\n",
    "        label = data.columns[0]\n",
    "        features= data.columns[1:]\n",
    "\n",
    "        data_features = data[features]\n",
    "        data_label = data[label]\n",
    "\n",
    "        data_features_np = data_features.to_numpy()\n",
    "        data_label_np = data_label.to_numpy()\n",
    "\n",
    "\n",
    "        for i in range(1000):\n",
    "            temp_result = []\n",
    "\n",
    "            sample = data_features_np[i]\n",
    "            temp_result.append(entropy(sample) / math.log2(65536))\n",
    "\n",
    "        result.append(np.mean(temp_result))\n",
    "        column_names.append(filename_suffix + str(center))\n",
    "        \n",
    "    result_pd = pd.DataFrame(result)\n",
    "    result_pd = result_pd.T\n",
    "    combined_result.append(result_pd.values[0])\n",
    "    result_pd.columns = column_names\n",
    "    result_pd.to_csv(output_filename, encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.19522197, 0.20973476, 0.21159158, 0.22209585, 0.22757416,\n",
      "       0.25437983, 0.23077546, 0.23159218, 0.22812616, 0.28523121,\n",
      "       0.25119942, 0.24555494, 0.24884813, 0.2380569 , 0.28950456,\n",
      "       0.24945212, 0.2542817 , 0.26975423]), array([0.30592297, 0.28282546, 0.26422266, 0.26082394, 0.24013652,\n",
      "       0.25696519, 0.22937138, 0.25138862, 0.29372132, 0.27814627,\n",
      "       0.25683348, 0.22632232, 0.2154335 , 0.20575532, 0.29006851,\n",
      "       0.22162756, 0.21606978, 0.32172086]), array([0.15321893, 0.13914826, 0.12813552, 0.11170619, 0.08956186,\n",
      "       0.11055172, 0.11801902, 0.15280319, 0.15899113, 0.15470526,\n",
      "       0.15239721, 0.13352074, 0.17897542, 0.21172184, 0.13847461,\n",
      "       0.24337716, 0.14462161, 0.16575377]), array([0.38375868, 0.43042118, 0.43977698, 0.44991187, 0.4479618 ,\n",
      "       0.49048929, 0.46971529, 0.42093384, 0.41619755, 0.437659  ,\n",
      "       0.43354841, 0.45971159, 0.41548182, 0.39445309, 0.4202197 ,\n",
      "       0.41038691, 0.40365529, 0.3942777 ])]\n"
     ]
    }
   ],
   "source": [
    "combined_column_names = ['10', '30', '50', '70', '90', '110', '130', '150', '170', '190', '210', '230', '250', '270', '290', '310', '330', '350']\n",
    "\n",
    "\n",
    "separate_labels_features(\"test_quantized_ecl_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "separate_labels_features(\"test_quantized_ecl_hungarian_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "separate_labels_features(\"test_quantized_js_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "separate_labels_features(\"test_quantized_js_hungarian_\", [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350])\n",
    "\n",
    "\n",
    "print(combined_result)\n",
    "\n",
    "combined_result_pd = pd.DataFrame(combined_result)\n",
    "combined_result_pd.columns = combined_column_names\n",
    "combined_result_pd.to_csv(\"combined_result_ecl_js.csv\", encoding='utf-8', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
